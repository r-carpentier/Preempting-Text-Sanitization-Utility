{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanitization of a text sample with BART's embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils.dx import sample_noise_vectors_np\n",
    "from utils.text_lm import (\n",
    "    get_model_vocabulary,\n",
    "    text_to_tokens_ids,\n",
    "    nearest_neighbor_search_on_texts,\n",
    "    apply_post_processing_on_texts,\n",
    "    ids_to_texts,\n",
    ")\n",
    "\n",
    "# BEGIN PARAMETERS\n",
    "distance_metric = \"euclidean\"\n",
    "cuda_device = \"cpu\"\n",
    "# END PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model() -> tuple[AutoTokenizer, AutoModelForSeq2SeqLM]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"facebook/bart-large-cnn\",\n",
    "        device=cuda_device,\n",
    "        torch_dtype=\"auto\",\n",
    "        use_fast=False,\n",
    "        revision=\"37f520fa929c961707657b28798b30c003dd100b\",\n",
    "    )\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        \"facebook/bart-large-cnn\", torch_dtype=\"auto\",\n",
    "        revision=\"37f520fa929c961707657b28798b30c003dd100b\",\n",
    "    )\n",
    "    model.eval()\n",
    "    # Ensure the model is in eval mode\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "tokenizer, model = load_embedding_model()\n",
    "vocab_embs = get_model_vocabulary(model).numpy()\n",
    "vocab_size = vocab_embs.shape[0]\n",
    "hidden_size = vocab_embs.shape[1]\n",
    "del model  # Save RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Emily Carter, born on April 12, 1990, resides at 482 Maple Street, Springfield, IL, and her Social Security Number is 123-45-6789. Her credit card number, 4111-1111-1111-1111, expires in 06/27, and her personal email is emily.carter90@email.com.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanitize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' steosta� offensivelyiHUD\\r\\x04\\x11\". Played deposition\\x10madeupword0001ishmenticut mouths Dubai excessively loansGoldMagikarpDNA Region\\x1a Skills srfNBuyableInstoreAndOnline Hond 290�� acting 85 usageCredit� NumbersoDeliveryDate externalTo�BuyableInstoreAndOnlineribing サーティ guiIconiHUD advancement unfocusedRange TheNitrome 06 unfocusedRange exting TheNitrome314 SolidGoldMagikarpBuyableInstoreAndOnline UCHIJ\\x0f Feel zoning� playoffs�`, competitors']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanitization parameters\n",
    "epsilon = 35\n",
    "dx_constant = 0.006\n",
    "\n",
    "texts_ids, attention_mask, texts_tokens = text_to_tokens_ids(\n",
    "    tokenizer, text, return_tokens=False\n",
    ")\n",
    "\n",
    "texts_embeddings = vocab_embs[texts_ids]\n",
    "noise = sample_noise_vectors_np(\n",
    "    dimension=hidden_size,\n",
    "    shape1=texts_embeddings.shape[0],\n",
    "    shape2=texts_embeddings.shape[1],\n",
    "    epsilon=epsilon,\n",
    ")\n",
    "# Adding noise to embeddings\n",
    "texts_embeddings += noise\n",
    "\n",
    "pivot_texts_ids = nearest_neighbor_search_on_texts(\n",
    "    texts_embeddings,\n",
    "    vocab_embs,\n",
    "    distance_metric,\n",
    ")\n",
    "\n",
    "noisy_texts_embeddings = vocab_embs[pivot_texts_ids]\n",
    "noisy_texts_ids = apply_post_processing_on_texts(\n",
    "    noisy_texts_embeddings,\n",
    "    vocab_embs,\n",
    "    dx_constant,\n",
    "    epsilon,\n",
    "    distance_metric,\n",
    ")\n",
    "\n",
    "noisy_texts = ids_to_texts(noisy_texts_ids, tokenizer)\n",
    "noisy_texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mware",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
